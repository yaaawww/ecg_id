{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5fab2e-75e4-45f0-a158-6c0484664513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# Mobile Net\n",
    "from torchvision.models.quantization.mobilenetv3 import mobilenet_v3_large\n",
    "from torch.quantization import prepare_qat, get_default_qat_qconfig, convert\n",
    "from torchvision.models import quantization\n",
    "from torch.quantization import QuantStub, DeQuantStub, quantize_dynamic, prepare_qat, convert\n",
    "# dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "# dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "# Util\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "# tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# plt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Noto Sans CJK JP'\n",
    "matplotlib.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e43e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "input_size = 224\n",
    "batch_size = 32\n",
    "n_worker = 8\n",
    "lr = 0.001\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "916c1c6f-6228-4d64-928d-68c045094bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练数据集\n",
    "train_path = \"image/train_image\"\n",
    "test_path = \"image/test_image\"\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize([input_size, input_size]),\n",
    "        transforms.ToTensor(),\n",
    "])\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=data_transform)\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a6157c-189f-46fc-9698-f8b99af5efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成数据加载器\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=n_worker, pin_memory=True)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=40, shuffle=False, \n",
    "    num_workers=n_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c7b0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型和优化器\n",
    "model = mobilenet_v3_large()\n",
    "model.classifier[3] = nn.Linear(1280, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30800540",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.training\n",
    "model.fuse_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88975106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lambd4/anaconda3/py39/lib/python3.9/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.qconfig = get_default_qat_qconfig(\"fbgemm\")\n",
    "model = prepare_qat(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01011a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total': 4253272, 'Trainable': 4253272}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_parameter_number(model):\n",
    "    total_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "get_parameter_number(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62637141",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda(3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "# writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75e7a13a-3f06-4de6-9e6a-cea34fa8c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data, label in train_loader:\n",
    "        data, label = data.cuda(3), label.cuda(3)\n",
    "        # clear the grad\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss function\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    # Re-quantize the model\n",
    "    # model = quantize_dynamic(model, {'': torch.quantization.default_dynamic_qconfig}, dtype=torch.qint8)\n",
    "    # writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "    # loss_vec32.append(train_loss)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24a8cfb1-cfaa-42ac-9fdd-fd1d708ac2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, model):\n",
    "    quantized_model = torch.quantization.convert(model.cpu().eval(), inplace=False)\n",
    "    quantized_model.eval()\n",
    "    idx = 0\n",
    "    ans = 0.0\n",
    "    best_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            output = quantized_model(data)\n",
    "            preds = torch.argmax(output, 1)\n",
    "            unique_values, counts = torch.unique(preds, return_counts=True)\n",
    "            pres = unique_values[counts.argmax()]\n",
    "            if pres.item() == idx:\n",
    "                ans += 1\n",
    "            idx += 1\n",
    "    acc = ans / 40\n",
    "    if acc > best_acc:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    print('Epoch: {} Accuracy: {:6f}'.format(epoch, ans / 40))\n",
    "    return ans / 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e2e2a-0723-4ceb-97ae-ec1f28316dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lambd4/anaconda3/py39/lib/python3.9/site-packages/torch/ao/quantization/fake_quantize.py:343: UserWarning: _aminmax is deprecated as of PyTorch 1.11 and will be removed in a future release. Use aminmax instead. This warning will only appear once per process. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/ReduceAllOps.cpp:72.)\n",
      "  return torch.fused_moving_avg_obs_fake_quant(\n",
      "/data/lambd4/anaconda3/py39/lib/python3.9/site-packages/torch/ao/quantization/fake_quantize.py:343: UserWarning: _aminmax is deprecated as of PyTorch 1.11 and will be removed in a future release. Use aminmax instead. This warning will only appear once per process. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorCompare.cpp:677.)\n",
      "  return torch.fused_moving_avg_obs_fake_quant(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.073403\n",
      "Epoch: 2 \tTraining Loss: 0.503185\n",
      "Epoch: 3 \tTraining Loss: 0.446780\n",
      "Epoch: 4 \tTraining Loss: 0.402719\n",
      "Epoch: 5 \tTraining Loss: 0.381998\n",
      "Epoch: 6 \tTraining Loss: 0.227516\n",
      "Epoch: 7 \tTraining Loss: 0.368299\n",
      "Epoch: 8 \tTraining Loss: 0.202324\n",
      "Epoch: 9 \tTraining Loss: 0.146318\n",
      "Epoch: 10 \tTraining Loss: 0.266481\n",
      "Epoch: 11 \tTraining Loss: 0.393295\n",
      "Epoch: 12 \tTraining Loss: 0.184169\n",
      "Epoch: 13 \tTraining Loss: 0.223331\n",
      "Epoch: 14 \tTraining Loss: 0.154920\n",
      "Epoch: 15 \tTraining Loss: 0.054038\n",
      "Epoch: 16 \tTraining Loss: 0.022082\n",
      "Epoch: 17 \tTraining Loss: 0.011152\n",
      "Epoch: 18 \tTraining Loss: 0.048746\n",
      "Epoch: 19 \tTraining Loss: 0.037339\n",
      "Epoch: 20 \tTraining Loss: 0.118830\n",
      "Epoch: 21 \tTraining Loss: 0.171060\n",
      "Epoch: 22 \tTraining Loss: 0.201511\n",
      "Epoch: 23 \tTraining Loss: 0.093984\n",
      "Epoch: 24 \tTraining Loss: 0.041430\n",
      "Epoch: 25 \tTraining Loss: 0.037189\n",
      "Epoch: 26 \tTraining Loss: 0.069660\n",
      "Epoch: 27 \tTraining Loss: 0.053549\n",
      "Epoch: 28 \tTraining Loss: 0.026414\n",
      "Epoch: 29 \tTraining Loss: 0.008537\n",
      "Epoch: 30 \tTraining Loss: 0.008074\n",
      "Epoch: 31 \tTraining Loss: 0.039750\n",
      "Epoch: 32 \tTraining Loss: 0.041187\n",
      "Epoch: 33 \tTraining Loss: 0.129118\n",
      "Epoch: 34 \tTraining Loss: 0.171126\n",
      "Epoch: 35 \tTraining Loss: 0.202860\n",
      "Epoch: 36 \tTraining Loss: 0.079013\n",
      "Epoch: 37 \tTraining Loss: 0.039281\n",
      "Epoch: 38 \tTraining Loss: 0.027888\n",
      "Epoch: 39 \tTraining Loss: 0.029892\n",
      "Epoch: 40 \tTraining Loss: 0.014184\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, model)\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print(f\"Training time {total_time_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算测试时间\n",
    "tic = time.time()\n",
    "test(1)\n",
    "toc = time.time()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "753f0644-def1-4c54-b8df-8fd6234d3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.strftime('%Y_%m_%d_%H_%M_%S', time.localtime())\n",
    "torch.save(model.load_state_dict(best_model_wts), f'save_model/ecgid_model_{s}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
